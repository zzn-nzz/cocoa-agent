"""
Controller classes for generating actions/commands to solve programming tasks.

This module provides a base Controller class and implementations for:
- LLM: Uses OpenAI API to generate actions
- Human: Prompts user for manual input
"""

import os
import re
import json
from typing import Any, Dict, List
from openai import OpenAI
from .utils import get_logger, colorize
from .tools import get_browser_tools, get_unified_tools, map_tool_call_to_action

logger = get_logger("llm")


def format_tools_as_text(tools: List[Dict[str, Any]]) -> str:
    """Convert OpenAI tool schema to text description for Qwen3-VL models.
    
    Args:
        tools: List of tool definitions in OpenAI format
        
    Returns:
        Formatted text description of all tools
    """
    tool_descriptions = []
    
    for tool in tools:
        func = tool.get("function", {})
        name = func.get("name", "")
        description = func.get("description", "")
        parameters = func.get("parameters", {})
        properties = parameters.get("properties", {})
        required = parameters.get("required", [])
        
        # Build parameter descriptions
        param_descriptions = []
        for param_name, param_info in properties.items():
            param_type = param_info.get("type", "string")
            param_desc = param_info.get("description", "")
            param_enum = param_info.get("enum")
            param_default = param_info.get("default")
            
            param_str = f"  - {param_name} ({param_type})"
            if param_desc:
                param_str += f": {param_desc}"
            if param_enum:
                param_str += f" [options: {', '.join(map(str, param_enum))}]"
            if param_default is not None:
                param_str += f" [default: {param_default}]"
            if param_name in required:
                param_str += " [required]"
            
            param_descriptions.append(param_str)
        
        # Format tool description
        tool_text = f"- {name}: {description}"
        if param_descriptions:
            tool_text += "\n" + "\n".join(param_descriptions)
        
        tool_descriptions.append(tool_text)
    
    return "\n\n".join(tool_descriptions)


# Unified agent prompts
UNIFIED_INITIAL_PROMPT_TEMPLATE = """
You are a powerful AI agent with access to a comprehensive sandbox environment. You can control a web browser, execute shell commands, manipulate files, and run Python code to solve complex, multi-domain tasks.

Task:
{instruction}

You have access to these tool categories:

**Browser Tools:**
- browser_click(x, y) or browser_click(): Click at coordinates (x, y) or current cursor position
- browser_type(text)
- browser_press(key)
- browser_move_to(x, y) / browser_move_rel(dx, dy): Move mouse cursor
- browser_drag_to(x, y) / browser_drag_rel(dx, dy): Drag mouse (use for scrolling: move to scrollbar, then drag)
- browser_hotkey(keys) / browser_key_down(key) / browser_key_up(key): Keyboard actions
- browser_wait(seconds): Wait for duration
- browser_double_click(x, y) / browser_right_click(x, y): Special click actions
- browser_screenshot(): Capture current viewport (image) - CRITICAL for visual observation
- browser_get_info(): Get current URL and viewport metadata
- browser_navigate(url): Navigate to a URL (DOM load)
- DOM tools (text-based, no vision): dom_get_text(), dom_get_html(), dom_query_selector(selector), dom_extract_links(filter_pattern?), dom_click(selector, nth=0, button=?, click_count=?)
- **Note**: `browser_scroll()` is unavailable. To scroll, use `browser_move_to()` to position on scrollbar, then `browser_drag_rel()` or `browser_drag_to()`, or use keyboard shortcuts like `browser_press("PageDown")` or `browser_hotkey(["ctrl", "end"])`.

**File Tools:**
- file_read, file_write, file_list: Basic file operations
- file_upload, file_download: Upload/download files between the sandbox (Docker container) and the host machine (especially for binary files). Note: These are NOT for downloading files from the browser to the sandbox file system. Use browser actions to interact with web pages, then use file operations to save content to the sandbox file system.
- image_read: Read image files (PNG, JPG, etc.) and return them as base64-encoded images for visual analysis. Use this to read visualization files generated by code (e.g., matplotlib plots, saved figures).
- replace_in_file, search_in_file, find_files: Advanced file operations
- str_replace_editor: Powerful file editing with view/create/replace/insert/undo

**Code Execution Tools:**
- code_execute: Run code via sandbox runtime (python default); returns stdout/stderr

**Shell Tools:**
- shell_execute: Execute bash commands in the sandbox

**Task Management:**
- task_complete: Mark task as complete

CRITICAL OPERATING RULES (follow exactly):
1. **Choose interaction mode (DOM-first, vision when needed)**
   - Prefer DOM/text tools when you can identify targets by selector/text (`dom_get_text/html`, `dom_query_selector`, `dom_extract_links`, `dom_click`).
   - Use vision/coords when DOM is insufficient or ambiguous. Before any visual click, take `browser_screenshot` to locate targets.

2. **Action → Verify loop**
   - Every browser action intended to change page state must be followed by verification:
     - `browser_screenshot()` and `browser_get_info()` to capture the new viewport and current URL.
     - Compare to prior screenshot/URL to confirm meaningful change.
   - If no meaningful change, treat the action as failed and choose a different action.

3. **Visual clicks need evidence**
   - For coordinates, `browser_click` ONLY accepts (x, y) or current cursor position.
   - Do NOT blindly retry the same coordinates more than 2 times unless you observed a state change in-between.

4. **Loop/Failure protection**
   - Keep a short action history. Do not repeat the exact same sequence of 4 actions.
   - If you make N=6 consecutive browser actions without verified progress, stop automated attempts and:
     - Summarize attempts and screenshots, and either switch strategy (e.g., to code_execute scraping) or request human intervention.
   # - If a page clearly shows an error (404, "Page not found", server error), DO NOT try to find elements on it. Navigate to a safe fallback (site root or other known canonical entry). (Navigation is temporarily disabled)

5. **No placeholders / no fabrication**
   - Never invent URLs, filenames, or data. Never use placeholder domains (example.com) as actual inputs.
   - If a required resource cannot be found, report what you searched and the screenshots/evidence.

6. **Download & file verification**
   - After downloading a file from the web (via browser actions), save it to the sandbox file system using `file_write` or other file operations.
   - Note: `file_download` is for transferring files between the sandbox container and the host machine, NOT for downloading from web browsers.
   - After saving a file, verify file existence and non-zero size via `file_list`/`file_read` or shell stat.
   - For PDFs or parsed documents, verify parsability (e.g., open via code_execute with a PDF parser and confirm expected sections exist).

7. **Use code_execute to implement missing capabilities**
   - If a necessary operation (e.g., advanced parsing, OCR, link discovery) is not supported by the sandbox tools, implement a robust helper in `code_execute`, then verify its output.

8. **Logging & milestones**
   - Record progress milestones to `/home/gem/task_progress.txt` with brief verification lines and the screenshot filenames used as evidence (e.g., "found_list_v1 — screenshot_01.png").

9. **Failure reporting**
   - If you cannot complete a subtask after reasonable attempts, produce a concise failure summary containing:
     - actions tried (with timestamps),
     - screenshot filenames,
     - why each attempt failed or was inconclusive,
     - suggested next steps or request for human input.

10. **Termination**
    - Call `task_complete` only after all required steps are correctly verified and persisted.

Behavioral guidance:
- Break tasks into short, verifiable steps.
- Prefer an extra screenshot + analysis over blind clicks.
- When switching strategy (browser → code), state the reason in one sentence.
- Avoid long speculative internal chains; instead return concrete actions and verification evidence.
"""

UNIFIED_FEEDBACK_PROMPT_TEMPLATE = """
Your previous actions have been executed. Here is the feedback:

{feedback}

Based on the feedback and your progress toward the goal, determine the next actions to take. You can call multiple tools in sequence.

Remember:
- Analyze what has been accomplished and what remains
- Use the appropriate tools (browser, file, code, shell) for each subtask
- Verify results when necessary
- **IMPORTANT**: When you have the final answer or result, you MUST call task_complete to finish the task. 
  - If the task requires returning a specific output (e.g., JSON answer), pass it as the 'result' parameter: task_complete(result="your_json_string")
  - If the task generates files in the sandbox (no specific output required), call task_complete() without parameters
- Call task_complete when the entire task is finished
"""


UNIFIED_INITIAL_PROMPT_TEMPLATE_QWEN3VL = """
You are a powerful AI agent with access to a comprehensive sandbox environment. You can control a web browser, execute shell commands, manipulate files, and run Python code to solve complex, multi-domain tasks.

Task:
{instruction}

{tools_description}

## Available Tools

### Browser Tools
- **Navigation & Info:**
  - `browser_screenshot()`: Capture current viewport (CRITICAL - primary observation channel)
  - `browser_get_info()`: Get current URL and viewport metadata
  - `browser_navigate(url)`: Navigate to a URL (DOM load)

- **Mouse Actions:**
  - `browser_click(x, y)` or `browser_click()`: Click at coordinates or current position
  - `browser_double_click(x, y)`: Double click
  - `browser_right_click(x, y)`: Right click
  - `browser_move_to(x, y)`: Move mouse to coordinates
  - `browser_move_rel(dx, dy)`: Move mouse relative to current position
  - `browser_drag_to(x, y)`: Drag to coordinates
  - `browser_drag_rel(dx, dy)`: Drag relative to current position

- **Keyboard Actions:**
  - `browser_type(text)`: Type text into focused element
  - `browser_press(key)`: Press a key (Enter, Tab, Escape, etc.)
  - `browser_key_down(key)`: Press and hold a key
  - `browser_key_up(key)`: Release a key
  - `browser_hotkey(keys)`: Press key combination (e.g., Ctrl+C)

- **Page Navigation:**
  - `browser_wait(seconds)`: Wait for specified duration
  - **Note**: `browser_scroll()` is currently unavailable. To scroll the page, use `browser_move_to()` to move the mouse to the scrollbar area, then use `browser_drag_rel()` or `browser_drag_to()` to drag the scrollbar. Alternatively, use keyboard shortcuts like `browser_press("PageDown")` or `browser_hotkey(["ctrl", "end"])` to navigate the page.

- **DOM/Text Actions (selector-based, no vision):**
  - `dom_get_text()`: Get page text (innerText of body, truncated if long)
  - `dom_get_html()`: Get page HTML (truncated if long)
  - `dom_query_selector(selector, limit=20)`: List elements with detailed attributes (tag, id, class, name, type, href, aria-label, role, text). Use to identify precise selectors before clicking.
  - `dom_extract_links(filter_pattern?, limit=50)`: Extract links (text + href) optionally filtered by substring
  - `dom_click(selector, nth=0, button?, click_count?)`: Click an element matched by CSS selector (0-based index)

### File Tools
- `file_read(path)`, `file_write(path, content)`, `file_list(path)`: Basic file operations
- `file_upload(file, path)`, `file_download(path)`: Upload/download files between the sandbox (Docker container) and the host machine (for binary files). **Important**: These tools are for transferring files between the sandbox container and the host machine, NOT for downloading files from web browsers to the sandbox file system. To save web content, first use browser actions to access the content, then use `file_write` or other file operations to save it within the sandbox.
- `image_read(path)`: Read image files (PNG, JPG, etc.) and return them as base64-encoded images for visual analysis. Use this to read visualization files generated by code (e.g., matplotlib plots, saved figures). The image will be automatically included in subsequent prompts for analysis.
- `replace_in_file(file, old_str, new_str)`, `search_in_file(file, regex)`, `find_files(path, glob)`: Advanced file operations
- `str_replace_editor(command, path, ...)`: Powerful file editing with view/create/replace/insert/undo

### Code Execution Tools
- `code_execute(code, language?, timeout?)`: Run code via sandbox runtime (python default); returns stdout/stderr

### Shell Tools
- `shell_execute(command)`: Execute bash commands in the sandbox

### Task Management
- `task_complete`: Mark task as complete when finished

## Important Guidelines (VLM-Aware - Follow Strictly)

### 1. Choose interaction mode (DOM-first, vision when needed)
- Prefer DOM/text tools when you can identify targets by selector/text (`dom_get_text/html`, `dom_query_selector`, `dom_extract_links`, `dom_click`).
- Use vision/coords when DOM is insufficient or ambiguous. Before any visual click, take `browser_screenshot` to locate targets.

### 2. Verify After Actions
- After each click/navigation: screenshot + get_info, then compare to previous state
- Treat an action as successful only if:
  - The URL changed meaningfully, OR
  - The page content (screenshot) changed meaningfully

### 4. Failure & Loop Safeguards
- Do not click the same selector or coordinates > 2 times unless a state change occurred
- If no verified progress after 6 browser actions:
  - Stop automated attempts
  - Produce a concise failure summary
  - Switch strategy (e.g., programmatic scraping with validated URLs) or request human input

### 5. Error Page Handling
- If screenshot or get_info shows an error page (404, maintenance, blocked):
  - Do NOT try to find elements there
  # - Navigate to a canonical entry (site root or known major index) or use a validated alternative resource (Navigation is temporarily disabled)

### 6. No Fabrication
- Do not invent URLs, file names, or other artifacts
- If a needed link isn't found, document screenshots and attempts
- Do not guess links

### 7. Download / Parse / Verify
- After accessing resources via browser (clicking download links, etc.):
  - Save the content to the sandbox file system using `file_write` or other file operations
  - Note: `file_download` is for transferring files between the sandbox container and the host machine, NOT for downloading from web browsers
  - Verify file existence
  - Verify that the file opens/parses correctly (use `code_execute` for parsing)
- For textual extraction failures, try OCR only after documenting attempts

### 8. Logging
- Log milestone entries to `/home/gem/task_progress.txt` with:
  - Short notes
  - Screenshot filenames used for decisions

### 9. When to Switch to Code Execution
- If browser-based visual exploration is failing due to dynamic content:
  - Document prior attempts first
  - Use `code_execute` only with validated URLs (never fabricated)

### 10. Termination
- Call `task_complete` only when:
  - All verification steps are satisfied
  - Results are persisted

## Tool Call Format

To call a tool, use this format:
<tool_call>
{{"name": "tool_name", "arguments": {{"param1": "value1", "param2": "value2"}}}}
</tool_call>

## Summary
Act visually, verify rigorously, and avoid blind exploration. Prefer one extra screenshot + VLM judgement before any ambiguous click.
"""

UNIFIED_FEEDBACK_PROMPT_TEMPLATE_QWEN3VL = """
Your previous actions have been executed. Here is the feedback:

{feedback}

Based on the feedback and your progress toward the goal, determine the next actions to take. You can call multiple tools in sequence.

Remember:
- Analyze what has been accomplished and what remains
- Use the appropriate tools (browser, file, code, shell) for each subtask
- Verify results when necessary
- **IMPORTANT**: When you have the final answer or result, you MUST call task_complete to finish the task.
  - If the task requires returning a specific output (e.g., JSON answer), pass it as the 'result' parameter: task_complete(result="your_json_string")
  - If the task generates files in the sandbox (no specific output required), call task_complete() without parameters
- Call task_complete when the entire task is finished
- To call a tool, use the format: <tool_call>
{{"name": "tool_name", "arguments": {{"param1": "value1", "param2": "value2"}}}}
</tool_call>
"""


class Controller:
    """Base class for controllers that generate actions given a prompt."""

    def call(self, prompt: str, message_history: List[Dict[str, Any]] | None = None) -> Dict[str, Any]:
        """Send a prompt and return the parsed action/response.

        Args:
            prompt: The prompt to send to the controller
            message_history: Optional list of previous messages for context

        Returns:
            Dictionary with keys:
            - command: The action/command to execute
            - explanation: Brief explanation of what the command does
        """
        raise NotImplementedError("Not implemented")

    def clear_history(self) -> None:
        """Clear any stored conversation history."""
        raise NotImplementedError("Not implemented")

    def build_prompt(self, task_description: str = None, feedback: str = None) -> str:
        """Build a prompt for the controller.

        Args:
            task_description: The task description
            feedback: Feedback from previous iteration

        Returns:
            A formatted prompt string
        """
        raise NotImplementedError("Not implemented")

    def parse_response(self, response: str) -> Dict[str, Any]:
        """Parse controller's response into a structured format.

        Args:
            response: The controller's raw response

        Returns:
            Dictionary with command and explanation
        """
        raise NotImplementedError("Not implemented")

    def get_history(self) -> List[Dict[str, str]]:
        """Get the message history. Can be overridden by subclasses."""
        return []

    def add_tool_message(self, tool_call_id: str, content: str) -> None:
        """Optional hook for controllers that maintain conversation history with tool outputs."""
        return


class LLM(Controller):
    """Language model client using OpenAI API."""

    def __init__(self, llm_config: Dict[str, Any] | None = None, client_type: str = "shell", **kwargs):
        if llm_config is None:
            llm_config = {}

        # Extract model and api_key from llm_config, with fallback to kwargs and env variables
        self.model = llm_config.get("model", kwargs.get("model", "gpt-4.1"))
        api_key = (
            llm_config.get("api_key") or
            kwargs.get("api_key") or
            os.getenv("OPENAI_API_KEY")
        )
        # Supports reading base_url from environment variables and falling back to local vLLM if no OpenAI key is provided
        base_url = (
            llm_config.get("base_url") or
            kwargs.get("base_url") or
            os.getenv("OPENAI_BASE_URL") or
            os.getenv("VLLM_BASE_URL")
        )

        # If no OpenAI key is found, but a base_url is configured/detected, set a placeholder key for vLLM compatibility
        if not api_key:
            if base_url:
                api_key = "EMPTY"  # vLLM does not validate the key, but OpenAI SDK requires a string
                logger.info("No OPENAI_API_KEY found. Using placeholder key for vLLM.")
            else:
                # If no key and no base_url, attempt to fall back to a local port-forwarded vLLM
                base_url = "http://localhost:8000/v1"
                api_key = "EMPTY"
                logger.info("No OPENAI_API_KEY or base_url provided. Falling back to local vLLM at http://localhost:8001/v1")

        # Initialize OpenAI client
        client_kwargs = {}
        if api_key:
            client_kwargs["api_key"] = api_key
        if base_url:
            client_kwargs["base_url"] = base_url

        self.client = OpenAI(**client_kwargs)
        self.messages: List[Dict[str, str]] = []
        self.last_think: str | None = None  # Store the last think/reasoning content for visualization
        
        # Store client type and determine tool usage
        self.client_type = client_type
        self.use_tools = client_type in ["browser", "file", "code", "jupyter", "shell", "unified"]
        self.max_parse_retries = max(1, int(llm_config.get("max_parse_retries", 2)))
        
        # Load appropriate tools based on client type
        if self.use_tools:
            from .tools import get_browser_tools, get_file_tools, get_code_tools, get_shell_tools, get_unified_tools
            if client_type == "unified":
                self.tools = get_unified_tools()
            elif client_type == "browser":
                self.tools = get_browser_tools()
            elif client_type == "file":
                self.tools = get_file_tools()
            elif client_type == "code" or client_type == "jupyter":
                self.tools = get_code_tools()
            elif client_type == "shell":
                self.tools = get_shell_tools()
            else:
                self.tools = None
        else:
            self.tools = None
        
        # Detect if using Qwen model (for special parsing)
        self.is_qwen_model = "qwen" in self.model.lower() if isinstance(self.model, str) else False
        
        # Detect if using Qwen3-VL model (for vision support)
        model_lower = self.model.lower() if isinstance(self.model, str) else ""
        self.is_qwen_vl_model = "qwen3-vl" in model_lower or "qwen3_vl" in model_lower

        logger.info(f"LLM initialized with model: {self.model}")
        if base_url:
            logger.info(f"Using custom base_url: {base_url}")
        logger.debug(f"API key configured: {bool(api_key)}")
        logger.debug(f"Client type: {self.client_type}")
        logger.debug(f"Tool calling mode: {self.use_tools}")
        logger.debug(f"Is Qwen model: {self.is_qwen_model}")
        logger.debug(f"Is Qwen3-VL model: {self.is_qwen_vl_model}")

    def call(self, prompt: str, images_base64: list = None) -> Dict[str, Any]:
        """Send prompt to OpenAI API and return parsed response.
        
        Args:
            prompt: The prompt string to send to the LLM
            images_base64: Optional list of base64-encoded image strings (for vision models)
                          Can also accept a single string for backward compatibility
            
        Returns:
            Parsed response dictionary with action information
        """
        # Handle backward compatibility: if single string is passed, convert to list
        if images_base64 is not None and isinstance(images_base64, str):
            images_base64 = [images_base64]
        
        # Build message content based on whether we have images
        if images_base64 and len(images_base64) > 0:
            # Build content list with text and all images
            message_content = []
            
            # Add text first (for OpenAI format) or after images (for Qwen3-VL)
            if self.is_qwen_vl_model:
                # Qwen3-VL format: images first, then text
                for img_base64 in images_base64:
                    message_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{img_base64}"
                        }
                    })
                message_content.append({
                    "type": "text",
                    "text": prompt
                })
            else:
                # OpenAI multimodal format: text first, then images
                message_content.append({
                    "type": "text",
                    "text": prompt
                })
                for img_base64 in images_base64:
                    message_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{img_base64}"
                        }
                    })
            logger.debug(f"Adding {len(images_base64)} image(s) to message (total size: {sum(len(img) for img in images_base64)} chars)")
        else:
            # Regular text message
            message_content = prompt

        self.messages.append({"role": "user", "content": message_content})

        attempt = 0
        max_attempts = self.max_parse_retries

        while attempt < max_attempts:
            attempt += 1
            logger.debug(f"Sending prompt to {self.model} (conversation depth: {len(self.messages)}, attempt {attempt}/{max_attempts})")

            try:
                # Prepare API call parameters
                api_params = {
                    "model": self.model,
                    "messages": self.messages
                }
                
                # Add tools if in tool calling mode (except for Qwen3-VL text-based tool calls)
                if self.use_tools and self.tools and not self.is_qwen_vl_model:
                    api_params["tools"] = self.tools
                
                response = self.client.chat.completions.create(**api_params)

                message = response.choices[0].message
                
                # Handle Qwen model special format (text-based tool calls)
                assistant_message = message.content if message.content else ""
                # Check for tool calls either by content pattern or model type
                has_tool_call_pattern = ("<tool_call>" in assistant_message or "</tool_call>" in assistant_message)
                if self.use_tools and assistant_message and (has_tool_call_pattern or self.is_qwen_model):
                    tool_calls = self.parse_text_tool_calls(assistant_message)
                    if tool_calls:
                        # Save think content (extract reasoning before tool calls) for visualization
                        # For Qwen, the think content is usually before <tool_call> tags
                        if "<tool_call>" in assistant_message:
                            think_part = assistant_message.split("<tool_call>")[0].strip()
                            self.last_think = think_part if think_part else None
                        else:
                            # For Qwen without tags, try to extract reasoning (content before tool calls)
                            self.last_think = assistant_message  # Use full content as think for now
                        
                        self.messages.append({"role": "assistant", "content": assistant_message})
                        
                        model_name = "Qwen3-VL" if has_tool_call_pattern else "Qwen"
                        logger.debug(f"Parsed {len(tool_calls)} tool calls from {model_name} model")
                        
                        try:
                            parsed_response = self.parse_tool_calls_list(tool_calls)
                            logger.debug(f"Parsed tool calls (ACTION): \n{colorize(json.dumps(parsed_response, indent=2), 'YELLOW')}")
                            return parsed_response
                        except ValueError as parse_error:
                            logger.warning(f"Failed to parse {model_name} tool calls (attempt {attempt}/{max_attempts}): {parse_error}")
                            if attempt >= max_attempts:
                                return {
                                    "action_type": "error",
                                    "error_message": str(parse_error),
                                    "tool_calls": tool_calls
                                }
                            error_message = (
                                f"Error parsing tool calls: {str(parse_error)}\n"
                                f"Please check the tool parameters and try again. "
                                f"Make sure you only use the parameters documented for each tool."
                            )
                            self.messages.append({
                                "role": "user",
                                "content": error_message
                            })
                            continue
                
                # Handle tool calling response (OpenAI format)
                if self.use_tools and hasattr(message, 'tool_calls') and message.tool_calls:
                    # Save think content (reasoning before action) for visualization
                    self.last_think = message.content if message.content else None
                    
                    self.messages.append({
                        "role": "assistant",
                        "content": message.content,
                        "tool_calls": [
                            {
                                "id": tc.id,
                                "type": tc.type,
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments
                                }
                            } for tc in message.tool_calls
                        ]
                    })
                    
                    logger.debug(f"Received {len(message.tool_calls)} tool calls from {self.model}")
                    
                    try:
                        parsed_response = self.parse_tool_calls(message.tool_calls)
                        logger.debug(f"Parsed tool calls (ACTION): \n{colorize(json.dumps(parsed_response, indent=2), 'YELLOW')}")
                        return parsed_response
                    except ValueError as parse_error:
                        logger.warning(f"Failed to parse tool calls (attempt {attempt}/{max_attempts}): {parse_error}")
                        # Add tool messages for each tool_call_id to satisfy OpenAI API requirements
                        # An assistant message with tool_calls must be followed by tool messages
                        for tc in message.tool_calls:
                            tool_call_id = getattr(tc, "id", None)
                            if tool_call_id:
                                error_content = f"Error parsing tool call: {str(parse_error)}"
                                self.add_tool_message(tool_call_id, error_content)
                        
                        if attempt >= max_attempts:
                            # On final attempt, return error action to be handled by agent loop
                            return {
                                "action_type": "error",
                                "error_message": str(parse_error),
                                "tool_calls": message.tool_calls
                            }
                        # Add error message to conversation and retry
                        error_message = (
                            f"Error parsing tool calls: {str(parse_error)}\n"
                            f"Please check the tool parameters and try again. "
                            f"Make sure you only use the parameters documented for each tool."
                        )
                        self.messages.append({
                            "role": "user",
                            "content": error_message
                        })
                        continue
                else:
                    # Regular text response (non-tool calling mode or no tools called)
                    # Save think content for visualization
                    self.last_think = assistant_message
                    self.messages.append({"role": "assistant", "content": assistant_message})

                    logger.debug(f"Received response from {self.model} (length: {len(assistant_message)} chars)")

                    try:
                        parsed_response = self.parse_response(assistant_message)
                        logger.debug(f"Parsed response (ACTION): \n{colorize(json.dumps(parsed_response, indent=2), 'YELLOW')}")
                        return parsed_response
                    except ValueError as parse_error:
                        logger.warning(f"Failed to parse assistant response (attempt {attempt}/{max_attempts}): {parse_error}")
                        if attempt >= max_attempts:
                            raise
                        correction_prompt = (
                            "Your previous response did not follow the required format. "
                            "Always respond with either (a) a tool call, or (b) a JSON object describing the next action "
                            "following this schema:\n"
                            "{\n"
                            '  "action_type": "<one of: browser_*, file_*, code_execute, shell_execute, task_complete>",\n'
                            '  "param_name": "param_value", ...\n'
                            "}\n"
                            "Do not nest parameters in a 'parameters' field. Put all parameters at the top level.\n"
                            "Do not include natural language outside the JSON object."
                        )
                        self.messages.append({
                            "role": "user",
                            "content": correction_prompt
                        })
                        continue
            except Exception as e:
                logger.error(f"Error calling OpenAI/VLLM API: {e}")
                logger.error("Hint: Ensure model name matches server (e.g., 'Qwen/Qwen3-32B') and base_url is set to your vLLM endpoint.")
                raise

        # If loop exits without return, raise error
        raise ValueError("Failed to obtain a valid action after retrying LLM response parsing.")

    def build_prompt(self, task_description: str = None, feedback: str = None, conversation_history: list = None) -> str:
        """Build the initial prompt for the LLM.
        
        Args:
            task_description: Initial task description (only used for first iteration)
            feedback: Feedback from previous actions
            conversation_history: List of previous conversation turns (commented out - using self.messages for context instead)
        """
        
        # For Qwen3-VL models, include tool descriptions in prompt
        tools_description = ""
        if self.is_qwen_vl_model and self.use_tools and self.tools:
            tools_description = format_tools_as_text(self.tools)
        
        if task_description is not None:
            # Initial prompt - only used for first iteration
            if self.is_qwen_vl_model:
                # Use Qwen3-VL specific templates with tool descriptions
                if self.client_type == "unified":
                    return UNIFIED_INITIAL_PROMPT_TEMPLATE_QWEN3VL.format(instruction=task_description, tools_description=tools_description)
            else:
                # Regular templates for non-Qwen3-VL models
                if self.client_type == "unified":
                    return UNIFIED_INITIAL_PROMPT_TEMPLATE.format(instruction=task_description)
        if feedback is not None:
            # Feedback prompt - only contains feedback, context is maintained in self.messages
            if self.is_qwen_vl_model:
                # Use Qwen3-VL specific templates
                if self.client_type == "unified":
                    return UNIFIED_FEEDBACK_PROMPT_TEMPLATE_QWEN3VL.format(feedback=feedback)
            else:
                # Regular templates for non-Qwen3-VL models
                if self.client_type == "unified":
                    return UNIFIED_FEEDBACK_PROMPT_TEMPLATE.format(feedback=feedback)
        raise ValueError("No task description or feedback provided")
    
    
    def parse_text_tool_calls(self, content: str) -> List[Dict[str, Any]]:
        """Parse Qwen model text-based tool calls.
        
        Qwen models return tool calls in format:
        <tool_call>
        {"name": "tool_name", "arguments": {...}}
        </tool_call>
        
        Or sometimes just:
        {"name": "tool_name", "arguments": {...}}
        </tool_call>
        
        Args:
            content: The model's text response
            
        Returns:
            List of tool call dictionaries
        """
        tool_calls = []
        import re
        
        # First, try to find complete tool_call blocks
        pattern = r'<tool_call>\s*({.*?})\s*</tool_call>'
        matches = re.findall(pattern, content, re.DOTALL)
        
        # If no complete blocks found, try to find JSON before </tool_call> tag
        if not matches:
            # Pattern: JSON object followed by </tool_call>
            pattern2 = r'({[^{}]*"name"[^{}]*})\s*</tool_call>'
            matches = re.findall(pattern2, content, re.DOTALL)
            # If still no matches, try a more flexible pattern
            if not matches:
                # Find JSON object that might be before </tool_call>
                pattern3 = r'({[^{}]*"name"[^{}]*"arguments"[^{}]*})'
                potential_matches = re.findall(pattern3, content, re.DOTALL)
                # Check if there's a </tool_call> tag nearby
                for potential in potential_matches:
                    # Check if this JSON is followed by </tool_call> within reasonable distance
                    idx = content.find(potential)
                    if idx != -1:
                        remaining = content[idx + len(potential):idx + len(potential) + 50]
                        if "</tool_call>" in remaining:
                            matches.append(potential)
                            break
        
        for match in matches:
            try:
                # First attempt: try to parse directly
                tool_call_data = json.loads(match)
            except json.JSONDecodeError as e:
                # Second attempt: try to fix control characters
                try:
                    fixed_match = self._fix_json_control_chars(match)
                    tool_call_data = json.loads(fixed_match)
                    logger.debug(f"Successfully parsed tool call after fixing control characters")
                except (json.JSONDecodeError, Exception) as e2:
                    logger.error(f"Failed to parse Qwen tool call: {e}")
                    logger.debug(f"JSON content (first 500 chars): {match[:500]}")
                    continue
            
            tool_calls.append({
                "function": {
                    "name": tool_call_data.get("name"),
                    "arguments": json.dumps(tool_call_data.get("arguments", {}))
                }
            })
        
        return tool_calls

    def _fix_json_control_chars(self, json_str: str) -> str:
        """Fix unescaped control characters in JSON string values.
        
        This handles the common case where code strings in tool arguments
        contain actual newlines, tabs, etc. that need to be escaped.
        
        Args:
            json_str: JSON string that may contain unescaped control characters
            
        Returns:
            Fixed JSON string with properly escaped control characters
        """
        result = []
        i = 0
        in_string = False
        escape_next = False
        
        while i < len(json_str):
            char = json_str[i]
            
            if escape_next:
                result.append(char)
                escape_next = False
            elif char == '\\':
                result.append(char)
                escape_next = True
            elif char == '"':
                result.append(char)
                in_string = not in_string
            elif in_string:
                # Inside a string, escape control characters
                if char == '\n':
                    result.append('\\n')
                elif char == '\r':
                    result.append('\\r')
                elif char == '\t':
                    result.append('\\t')
                elif char == '\b':
                    result.append('\\b')
                elif char == '\f':
                    result.append('\\f')
                elif ord(char) < 32:  # Other control characters (0x00-0x1F)
                    result.append(f'\\u{ord(char):04x}')
                else:
                    result.append(char)
            else:
                result.append(char)
            
            i += 1
        
        return ''.join(result)
    
    def parse_tool_calls_list(self, tool_calls: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Parse a list of tool calls (from Qwen or OpenAI format).
        
        Args:
            tool_calls: List of tool call dictionaries
            
        Returns:
            Dictionary with actions list or single action
        """
        actions = []
        
        for tool_call in tool_calls:
            function = tool_call.get("function", {})
            tool_call_id = tool_call.get("id")
            tool_name = function.get("name")
            try:
                arguments_str = function.get("arguments", "{}")
                if isinstance(arguments_str, str):
                    arguments = json.loads(arguments_str)
                else:
                    arguments = arguments_str
            except json.JSONDecodeError:
                logger.error(f"Failed to parse tool arguments: {function.get('arguments')}")
                arguments = {}
            
            # Map tool call to action
            from .tools import map_tool_call_to_action
            action = map_tool_call_to_action(tool_name, arguments)
            if tool_call_id:
                action["tool_call_id"] = tool_call_id
            actions.append(action)
            logger.debug(f"Tool call: {tool_name} -> Action: {action}")
        
        # If only one action, return it directly; otherwise return list
        if len(actions) == 1:
            return actions[0]
        else:
            return {"actions": actions}
    
    def parse_tool_calls(self, tool_calls) -> Dict[str, Any]:
        """Parse tool calls from OpenAI API response into action format.
        
        Args:
            tool_calls: List of tool calls from OpenAI API
            
        Returns:
            Dictionary with actions list or single action
        """
        # Convert OpenAI tool_calls to our internal format
        tool_calls_list = []
        for tc in tool_calls:
            tool_calls_list.append({
                "id": getattr(tc, "id", None),
                "function": {
                    "name": tc.function.name,
                    "arguments": tc.function.arguments
                }
            })
        
        return self.parse_tool_calls_list(tool_calls_list)

    def parse_response(self, response: str) -> Dict[str, Any]:
        """Parse JSON from the LLM response."""
        # Check if response contains tool_call tags (Qwen format) - if so, try to parse as tool call first
        if self.use_tools and ("<tool_call>" in response or "</tool_call>" in response):
            tool_calls = self.parse_text_tool_calls(response)
            if tool_calls:
                logger.debug(f"Found tool_call tags in response, parsed {len(tool_calls)} tool calls")
                parsed_response = self.parse_tool_calls_list(tool_calls)
                if parsed_response:
                    return parsed_response[0] if isinstance(parsed_response, list) else parsed_response
        
        # Qwen models often prepend a `<think>...</think>` block; only parse content after it
        try:
            model_name = getattr(self, "model", "")
            if isinstance(model_name, str) and "qwen" in model_name.lower():
                lower = response.lower()
                if "<think>" in lower:
                    end_tag = "</think>"
                    if end_tag in lower:
                        idx = lower.rfind(end_tag)
                        response = response[idx + len(end_tag):]
                    else:
                        open_idx = lower.find("<think>")
                        response = response[open_idx + len("<think>"):]
        except Exception:
            pass
        
        # Remove tool_call tags if present (in case they weren't parsed above)
        if "<tool_call>" in response or "</tool_call>" in response:
            # Try to extract JSON from tool_call tags
            pattern = r'<tool_call>\s*({.*?})\s*</tool_call>'
            match = re.search(pattern, response, re.DOTALL)
            if match:
                response = match.group(1)
                logger.debug(f"Extracted JSON from tool_call tags: {response[:200]}...")
        
        # Try to find JSON in markdown code block
        json_match = re.search(r"```(?:json)?\s*\n?(.*?)\n?```", response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1).strip()
            # logger.debug(f"Found JSON in markdown code block: {json_str}")
        else:
            # Try to parse the entire response as JSON
            json_str = response.strip()
            logger.debug(f"No markdown code block found, attempting to parse raw response: {json_str}")

        try:
            parsed = json.loads(json_str)
            logger.debug(f"Successfully parsed JSON response with keys: {list(parsed.keys())}")
            return parsed
        except json.JSONDecodeError as e:
            # Attempt to auto-fix invalid backslash escapes common in shell commands
            try:
                fixed_json_str = re.sub(r"\\(?![\"\\/bfnrtu])", r"\\\\", json_str)
                parsed = json.loads(fixed_json_str)
                logger.debug("Successfully parsed JSON after fixing invalid escapes")
                return parsed
            except json.JSONDecodeError as e2:
                logger.error(f"Failed to parse JSON response: {e2}")
                logger.error(f"Response content: {response[:200]}...")
                raise ValueError(f"Invalid JSON in LLM response: {e2}")

    def get_history(self) -> List[Dict[str, str]]:
        """Get the message history."""
        return self.messages

    def clear_history(self) -> None:
        """Clear the message history."""
        logger.debug(f"Clearing message history ({len(self.messages)} messages removed)")
        self.messages = []
        self.last_think = None
    
    def get_last_think(self) -> str | None:
        """Get the last think/reasoning content for visualization.
        
        Returns:
            The last think content string, or None if not available
        """
        return self.last_think

    def add_tool_message(self, tool_call_id: str, content: str) -> None:
        """Append tool call results to the conversation history for OpenAI tool-calling compliance."""
        if not tool_call_id:
            return
        if content is None:
            content = ""
        if not isinstance(content, str):
            content = str(content)
        tool_message = {
            "role": "tool",
            "tool_call_id": tool_call_id,
            "content": content
        }
        self.messages.append(tool_message)
        logger.debug(f"Added tool message for {tool_call_id}: {content[:200]}")


class Human(Controller):
    """Human controller that prompts user for manual input."""

    def __init__(self):
        """Initialize the Human controller."""
        logger.info("Human controller initialized")

    def call(self, prompt: str, message_history: List[Dict[str, Any]] | None = None) -> Dict[str, Any]:
        """Prompt user for manual input given a prompt.

        Args:
            prompt: The prompt to display to the user
            message_history: Ignored for Human controller

        Returns:
            Dictionary with command and explanation
        """
        logger.debug(f"Prompting user with: {prompt[:100]}...")
        print("\n" + "=" * 80)
        print("PROMPT:")
        print("=" * 80)
        print(prompt)
        print("=" * 80)
        print("Please provide your response below:")
        print("=" * 80)

        user_input = input("> ").strip()
        logger.debug(f"User provided input: {user_input[:100]}...")

        # Parse and return the structured response
        parsed_response = self.parse_response(user_input)
        return parsed_response

    def clear_history(self) -> None:
        """Human controller doesn't maintain history."""
        logger.debug("Human controller has no history to clear")

    def build_prompt(self, task_description: str = None, feedback: str = None) -> str:
        """Build a prompt for the human user.

        Args:
            task_description: The task description
            feedback: Feedback from previous iteration

        Returns:
            A formatted prompt string
        """
        if task_description is not None:
            prompt = f"Task: {task_description}\n\nPlease provide a shell command to solve this task."
            logger.debug(f"Built initial prompt for task: {prompt}")
            return prompt
        if feedback is not None:
            prompt = f"Feedback: {feedback}\n\nPlease provide the next shell command."
            logger.debug(f"Built feedback prompt: {prompt}")
            return prompt
        raise ValueError("No task description or feedback provided")

    def parse_response(self, response: str) -> Dict[str, Any]:
        """Parse user's response as a simple shell command.

        Args:
            response: The user's input response (plain shell command)

        Returns:
            Dictionary with command and explanation
        """
        command = response.strip()
        logger.debug(f"Parsed user command: {command[:100]}...")
        return {"command": command, "explanation": "User provided command"}
